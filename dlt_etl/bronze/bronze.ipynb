{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, col, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = spark.conf.get(\"catalog\")\n",
    "schema_landing = spark.conf.get(\"schema_landing\")\n",
    "schema_bronze = spark.conf.get(\"schema_bronze\")\n",
    "schema_silver = spark.conf.get(\"schema_silver\")\n",
    "schema_gold = spark.conf.get(\"schema_gold\")\n",
    "volume = spark.conf.get(\"volume\")\n",
    "BUCKET_NAME = spark.conf.get(\"bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ae373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bucket path-\n",
    "cloud_path = f\"s3a://{BUCKET_NAME}/raw_weather/\"\n",
    "\n",
    "# UC Volume used for Auto Loader schema tracking (required for schema drift)\n",
    "schema_path = f\"/Volumes/{catalog}/{schema_landing}/{volume}/schemas/iot_bronze/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment=\"Bronze layer: raw IoT weather data\"\n",
    ")\n",
    "def bronze_table():\n",
    "\n",
    "    df = (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "            # --- 1. Auto Loader Format & Inference ---\n",
    "            .option(\"cloudFiles.format\", \"json\")\n",
    "            .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "\n",
    "            # --- 2. Schema Persistence for UC ---\n",
    "            .option(\"cloudFiles.schemaLocation\", schema_path)\n",
    "\n",
    "            # --- 3. Force high-precision timestamp inference ---\n",
    "            .option(\"cloudFiles.schemaHints\", \"ingest_timestamp TIMESTAMP\")\n",
    "\n",
    "            # --- 4. Include/Exclude historical files ---\n",
    "            .option(\"cloudFiles.includeExistingFiles\", \"true\")\n",
    "\n",
    "            # --- 5. Source path (external volume) ---\n",
    "            .load(cloud_path)\n",
    "            )\n",
    "        \n",
    "    df = df.withColumn(\"_ingest_timestamp\", current_timestamp()) \\\n",
    "        .withColumn(\"_ingest_file_name\", col(\"_metadata.file_name\")) \\\n",
    "        .withColumn(\"_ingest_file_path\", col(\"_metadata.file_path\")) \\\n",
    "        .withColumn(\"ingestion_date\", to_date(\"_ingest_timestamp\"))\n",
    "    \n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
