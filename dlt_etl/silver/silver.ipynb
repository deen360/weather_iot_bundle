{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507239fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T\n",
    "import dlt\n",
    "from local_time.local_utils import add_local_time\n",
    "from day_time.day_utils import add_daytime_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment=\"Silver layer: cleaned and enriched IoT weather data\"\n",
    ")\n",
    "def silver_table():\n",
    "    \n",
    "\n",
    "    # Read bronze table using DLT semantics (incremental)\n",
    "    bronze_df = dlt.readStream(\"bronze_table\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1. Select & cast columns\n",
    "    # ------------------------------------------------------------\n",
    "    df_new = bronze_df.select(\n",
    "\n",
    "        # Identity & Location\n",
    "        F.sha2(F.concat_ws(\"_\", F.col(\"id\"), F.col(\"dt\")), 256).alias(\"event_uuid\"),\n",
    "        F.col(\"id\").cast(T.StringType()).alias(\"city_id\"),\n",
    "        F.col(\"name\").cast(T.StringType()).alias(\"name\"),\n",
    "        F.col(\"sys.country\").cast(T.StringType()).alias(\"country\"),\n",
    "        F.col(\"coord.lat\").cast(T.DecimalType(10, 2)).alias(\"latitude\"),\n",
    "        F.col(\"coord.lon\").cast(T.DecimalType(10, 2)).alias(\"longitude\"),\n",
    "        F.col(\"timezone\").cast(T.IntegerType()).alias(\"timezone\"),\n",
    "\n",
    "        # Time Dimensions\n",
    "        F.col(\"dt\").cast(T.TimestampType()).alias(\"datetime\"),\n",
    "        F.col(\"sys.sunrise\").cast(T.TimestampType()).alias(\"sunrise\"),\n",
    "        F.col(\"sys.sunset\").cast(T.TimestampType()).alias(\"sunset\"),\n",
    "\n",
    "        # Weather Metrics â€“ Main\n",
    "        F.col(\"main.temp\").cast(T.DecimalType(10, 2)).alias(\"temperature\"),\n",
    "        F.col(\"main.feels_like\").cast(T.DecimalType(10, 2)).alias(\"feels_like\"),\n",
    "        F.col(\"main.temp_min\").cast(T.DecimalType(10, 2)).alias(\"temperature_min\"),\n",
    "        F.col(\"main.temp_max\").cast(T.DecimalType(10, 2)).alias(\"temperature_max\"),\n",
    "        F.col(\"main.humidity\").cast(T.IntegerType()).alias(\"humidity\"),\n",
    "        F.col(\"main.pressure\").cast(T.IntegerType()).alias(\"pressure\"),\n",
    "        F.col(\"main.sea_level\").cast(T.IntegerType()).alias(\"main_sea_level\"),\n",
    "        F.col(\"main.grnd_level\").cast(T.IntegerType()).alias(\"main_grnd_level\"),\n",
    "\n",
    "        # Atmosphere\n",
    "        F.col(\"weather\")[0][\"main\"].cast(T.StringType()).alias(\"weather_main\"),\n",
    "        F.col(\"weather\")[0][\"description\"].cast(T.StringType()).alias(\"weather_description\"),\n",
    "        F.col(\"weather\")[0][\"icon\"].cast(T.StringType()).alias(\"weather_icon\"),\n",
    "        F.col(\"weather\")[0][\"id\"].cast(T.IntegerType()).alias(\"weather_id\"),\n",
    "        F.col(\"visibility\").cast(T.IntegerType()).alias(\"visibility\"),\n",
    "        F.col(\"clouds.all\").cast(T.IntegerType()).alias(\"clouds_all\"),\n",
    "        F.col(\"rain.1h\").cast(T.DecimalType(10, 2)).alias(\"rain_1h\"),\n",
    "\n",
    "        # Wind\n",
    "        F.col(\"wind.speed\").cast(T.DecimalType(10, 2)).alias(\"windspeed\"),\n",
    "        F.col(\"wind.gust\").cast(T.DecimalType(10, 2)).alias(\"wind_gust\"),\n",
    "        F.col(\"wind.deg\").cast(T.IntegerType()).alias(\"wind_deg\"),\n",
    "\n",
    "        # Technical Metadata\n",
    "        F.col(\"base\").cast(T.StringType()).alias(\"base\"),\n",
    "        F.col(\"cod\").cast(T.IntegerType()).alias(\"cod\"),\n",
    "        F.col(\"sys.id\").cast(T.IntegerType()).alias(\"sys_id\"),\n",
    "        F.col(\"sys.type\").cast(T.IntegerType()).alias(\"sys_type\"),\n",
    "        F.col(\"ingestion_date\").cast(T.DateType()).alias(\"ingestion_date\"),\n",
    "\n",
    "        # Ingestion Metadata\n",
    "        F.struct(\n",
    "            F.col(\"_ingest_timestamp\").cast(T.TimestampType()).alias(\"timestamp\"),\n",
    "            F.col(\"_ingest_file_name\").alias(\"file_name\"),\n",
    "            F.col(\"_ingest_file_path\").alias(\"file_path\"),\n",
    "            F.col(\"_rescued_data\").alias(\"rescued_data\")\n",
    "        ).alias(\"metadata\")\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2. Add local time\n",
    "    # ------------------------------------------------------------\n",
    "    df_local = add_local_time(\n",
    "        df=df_new,\n",
    "        datetime_col=\"datetime\",\n",
    "        timezone_col=\"timezone\",\n",
    "        output_col=\"local_time\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3. Add daytime flag\n",
    "    # ------------------------------------------------------------\n",
    "    df_normalized = add_daytime_flag(\n",
    "        df=df_local,\n",
    "        datetime_col=\"datetime\",\n",
    "        sunrise_col=\"sunrise\",\n",
    "        sunset_col=\"sunset\",\n",
    "        output_col=\"is_daytime\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4. Data Quality Rules\n",
    "    # ------------------------------------------------------------\n",
    "    rule_geo = (F.col(\"latitude\").between(-90, 90)) & (F.col(\"longitude\").between(-180, 180))\n",
    "    rule_time = F.col(\"datetime\").isNotNull()\n",
    "    rule_temp = F.col(\"temperature\").isNotNull()\n",
    "\n",
    "    dq_df = (\n",
    "        df_normalized\n",
    "        .withColumn(\"is_valid_geo\", rule_geo)\n",
    "        .withColumn(\"is_valid_timestamp\", rule_time)\n",
    "        .withColumn(\"is_valid_sensor\", rule_temp)\n",
    "        .withColumn(\n",
    "            \"dq_status\",\n",
    "            F.when(rule_geo & rule_time & rule_temp, \"PASS\").otherwise(\"FAIL\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"failure_reason\",\n",
    "            F.concat_ws(\n",
    "                \"; \",\n",
    "                F.when(~rule_geo, \"INVALID_GEO\"),\n",
    "                F.when(~rule_time, \"NULL_TIME\"),\n",
    "                F.when(~rule_temp, \"NULL_TEMP\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5. Filter PASS rows only\n",
    "    # ------------------------------------------------------------\n",
    "    clean_df = dq_df.filter(\"dq_status = 'PASS'\") \\\n",
    "        .drop(\"dq_status\", \"is_valid_geo\", \"is_valid_timestamp\", \"is_valid_sensor\", \"failure_reason\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6. Final column ordering (metadata at the end)\n",
    "    # ------------------------------------------------------------\n",
    "    return clean_df.select(\n",
    "        *[c for c in clean_df.columns if c != \"metadata\"],\n",
    "        \"metadata\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
