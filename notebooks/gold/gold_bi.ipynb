{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession \n",
    "spark = DatabricksSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507239fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema_landing = dbutils.widgets.get(\"schema_landing\")\n",
    "schema_silver = dbutils.widgets.get(\"schema_silver\")\n",
    "schema_gold = dbutils.widgets.get(\"schema_gold\")\n",
    "volume = dbutils.widgets.get(\"volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85bc3d",
   "metadata": {},
   "source": [
    "**LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a385654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Load silver Delta table \n",
    "# ----------------------------\n",
    "\n",
    "source_table = f\"{catalog}.{schema_silver}.weather_clean\"\n",
    "silver_df = spark.readStream.table(source_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19161c6a",
   "metadata": {},
   "source": [
    "**BI GOLD Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723a1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table_bi = f\"{catalog}.{schema_gold}.bi_weather_observations\"\n",
    "checkpoint_bi   = f\"/Volumes/{catalog}/{schema_landing}/{volume}/checkpoints/iot_gold/bi_obs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2548e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bi = (\n",
    "    silver_df\n",
    "    .select(\n",
    "        # ---------------------------\n",
    "        # 1. Location / Entity\n",
    "        # ---------------------------\n",
    "        F.col(\"city_id\"),\n",
    "        F.col(\"name\").alias(\"city_name\"),\n",
    "        F.col(\"country\").alias(\"country_code\"),\n",
    "\n",
    "        # ---------------------------\n",
    "        # 2. Time (Local + UTC)\n",
    "        # ---------------------------\n",
    "        F.col(\"local_time\").alias(\"observation_time_local\"),\n",
    "        F.col(\"datetime\").alias(\"observation_time_utc\"),\n",
    "\n",
    "        # ---------------------------\n",
    "        # 3. Temperature (explicit units)\n",
    "        # ---------------------------\n",
    "        F.round(\"temperature\", 1).alias(\"temperature_c\"),\n",
    "        F.round(\"feels_like\", 1).alias(\"feels_like_c\"),\n",
    "        F.round(\"temperature_min\", 1).alias(\"temp_min_c\"),\n",
    "        F.round(\"temperature_max\", 1).alias(\"temp_max_c\"),\n",
    "\n",
    "        # ---------------------------\n",
    "        # 4. Atmosphere\n",
    "        # ---------------------------\n",
    "        F.col(\"humidity\").alias(\"humidity_pct\"),\n",
    "        F.col(\"pressure\").alias(\"pressure_hpa\"),\n",
    "        F.col(\"clouds_all\").alias(\"cloud_cover_pct\"),\n",
    "\n",
    "        # ---------------------------\n",
    "        # 5. Conditions (human readable)\n",
    "        # ---------------------------\n",
    "        F.col(\"weather_main\").alias(\"condition_category\"),\n",
    "        F.initcap(\"weather_description\").alias(\"condition_text\"),\n",
    "        F.col(\"weather_icon\"),\n",
    "\n",
    "        # ---------------------------\n",
    "        # 6. Wind\n",
    "        # ---------------------------\n",
    "        F.round(\"windspeed\", 1).alias(\"wind_speed_ms\"),\n",
    "        F.col(\"wind_deg\").alias(\"wind_direction_deg\"),\n",
    "        F.round(\"wind_gust\", 1).alias(\"wind_gust_ms\"),\n",
    "\n",
    "        # ---------------------------\n",
    "        # 7. Rain (clean nulls)\n",
    "        # ---------------------------\n",
    "        F.coalesce(\"rain_1h\", F.lit(0.0)).alias(\"rain_mm\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5b5968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.streaming.query.StreamingQuery at 0x22cc80fe750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_bi.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", checkpoint_bi)\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(target_table_bi)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311a1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>{'numFilesAdded': 0, 'numFilesRemoved': 0, 'filesAdded': {'min': None, 'max': None, 'avg': 0.0, 'totalFiles': 0, 'totalSize': 0}, 'filesRemoved': {'min': None, 'max': None, 'avg': 0.0, 'totalFiles': 0, 'totalSize': 0}, 'partitionsOptimized': 0, 'zOrderStats': None, 'clusteringStats': None, 'numBins': 0, 'numBatches': 0, 'totalConsideredFiles': 0, 'totalFilesSkipped': 0, 'preserveInsertionOrder': True, 'numFilesSkippedToReduceWriteAmplification': 0, 'numBytesSkippedToReduceWriteAmplification': 0, 'startTimeMs': 1770579844772, 'endTimeMs': 1770579845558, 'totalClusterParallelism': 8, 'totalScheduledTasks': 0, 'autoCompactParallelismStats': None, 'deletionVectorStats': {'numDeletionVectorsRemoved': 0, 'numDeletionVectorRowsRemoved': 0}, 'recompressionCodec': None, 'numTableColumns': 19, 'numTableColumnsWithStats': 19, 'totalTaskExecutionTimeMs': 0, 'skippedArchivedFiles': 0, 'clusteringMetrics': None}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,recompressionCodec:string,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,isFull:boolean,approxClusteringQuality:double,approxClusteringQualityPerColumn:array<double>,approxClusteringCoverage:double,compactionType:string,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numIdealFilesWithTrimmedStringMaxValue:bigint,numAddedFilesWithSameMinMaxOnClusteringColumns:array<bigint>,numClusteringTasksPlanned:int,numClusteringTasksNotPlannedDueToPO:int,numCompactionTasksPlanned:int,numCompactionTasksPlannedUndoneDueToPO:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numLeafNodesCompactedUndoneDueToPO:bigint,numIntermediateNodesCompacted:bigint,numIntermediateNodesCompactedUndoneDueToPO:bigint,totalSizeOfDataToCompactInBytes:bigint,totalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. BI OBSERVATIONS (Reporting Layer)\n",
    "# ==============================================================================\n",
    "# BI dashboards almost always filter by City first (\"Show me London\") \n",
    "# and then by Date Range (\"Last 7 days\").\n",
    "# Clustering ensures all London data for a specific week is packed into ONE file,\n",
    "# allowing the dashboard to skip 99% of the data instantly.\n",
    "spark.sql(f\"OPTIMIZE {catalog}.{schema_gold}.bi_weather_observations\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
